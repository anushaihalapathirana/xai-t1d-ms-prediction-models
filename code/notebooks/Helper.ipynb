{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d814f4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "import numpy\n",
    "import math\n",
    "import shap \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as ltb\n",
    "\n",
    "from functools import reduce\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, SelectPercentile\n",
    "from sklearn.metrics import confusion_matrix, classification_report, f1_score, auc, roc_curve, roc_auc_score, precision_score, recall_score, balanced_accuracy_score\n",
    "from numpy.random import seed\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score, KFold, StratifiedKFold\n",
    "seed(42)\n",
    "tf.random.set_seed(38)\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a27f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function will return variable list that have correlation more than cut(0.8)\n",
    "\n",
    "def find_correlated_features(df, threshold=0.8):\n",
    "    corr_matrix = df.corr().abs()\n",
    "    avg_corr = corr_matrix.mean(axis=1)\n",
    "    upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    drop_columns = []\n",
    "\n",
    "    for row in range(len(upper_triangle) - 1):\n",
    "        col_idx = row + 1\n",
    "        for col in range(col_idx, len(upper_triangle)):\n",
    "            if upper_triangle.iloc[row, col] > threshold:\n",
    "                if avg_corr.iloc[row] > avg_corr.iloc[col]:\n",
    "                    drop_columns.append(row)\n",
    "                else:\n",
    "                    drop_columns.append(col)\n",
    "\n",
    "    drop_columns = set(drop_columns)\n",
    "    correlated_features = df.columns[list(drop_columns)]\n",
    "    \n",
    "    return correlated_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c58c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_val_percentage(df):\n",
    "    return (df.isnull().sum()* 100 / len(df))\n",
    "\n",
    "def preprocessing(df, test_size, response_variable, thresh = 40, isms = False, skip_corr = False):\n",
    "    keep = [ ]\n",
    "    rem = []\n",
    "    # Convert categorical and boolean varialbles to numeric using LabelEncoder\n",
    "#     cat_cols = df.select_dtypes(include=['bool', 'object']).columns\n",
    "#     for col in cat_cols:\n",
    "#         labelencoder = LabelEncoder()\n",
    "#         df[col] = labelencoder.fit_transform(df[col])\n",
    "        \n",
    "    # remove rows with missing 'response variable'\n",
    "#     df = df.dropna(how='any', subset = [response_variable])\n",
    "#     print('Shape of data after excluding missing response:', np.shape(df))\n",
    "    \n",
    "    # delete columns with more than threshold NaN\n",
    "    # get missing values < threshold feature name list\n",
    "    missing_per = get_missing_val_percentage(df)     \n",
    "    keep = df.columns[missing_per <= thresh]\n",
    "    df = df[keep]\n",
    "    print('Shape of data after removing cols with less than %.2f percent values missing:' % (thresh), df.shape)\n",
    "   \n",
    "    if not skip_corr:\n",
    "        # remove correlated features \n",
    "        df = df.drop([x for x in correlated_variables if x in df.columns], axis=1)\n",
    "        print('Shape of data after removing correlated features:', np.shape(df))\n",
    "\n",
    "    \n",
    "    # split data\n",
    "    random.seed(42)\n",
    "    # Save original data set\n",
    "    original = df\n",
    "    Y = df[response_variable]\n",
    "    X = df.drop(response_variable, axis=1)\n",
    "    if isms:\n",
    "        splitter = GroupShuffleSplit(test_size=0.25, n_splits=1, random_state = 123)\n",
    "        split = splitter.split(df, groups = df['patient.id'])\n",
    "        train_inds, test_inds = next(split)\n",
    "\n",
    "        train = df.iloc[train_inds]\n",
    "        test = df.iloc[test_inds]\n",
    "\n",
    "        groups =  np.array(train['patient.id'])\n",
    "        X_train = train.drop([response_variable,'patient.id'], axis = 1)\n",
    "        X_test = test.drop([response_variable, 'patient.id'], axis = 1)\n",
    "        Y_train = train[response_variable]\n",
    "        Y_test = test[response_variable]\n",
    "    else:\n",
    "        # Split into training and testing sets\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=123, stratify=Y)\n",
    "    \n",
    "    # data imputation\n",
    "    original_X_train = X_train\n",
    "    original_X_test = X_test\n",
    "    \n",
    "    imputer = SimpleImputer(missing_values=np.nan, strategy = \"most_frequent\")\n",
    "    # imputeX = KNNImputer(missing_values=np.nan, n_neighbors = 3, weights='distance')\n",
    "    # imputeX = IterativeImputer(max_iter=5, random_state=0)\n",
    "    X_train_imputed = imputer.fit_transform(X_train)\n",
    "    X_test_imputed = imputer.transform(X_test)\n",
    "    \n",
    "    # scale data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler2 = MinMaxScaler()\n",
    "    \n",
    "    select = {}\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train_imputed = scaler2.fit_transform(X_train_imputed)\n",
    "    X_test_imputed = scaler2.transform(X_test_imputed)\n",
    "        \n",
    "    # print unique value count of response variable in train and test set\n",
    "    unique_train, counts_train = numpy.unique(Y_train.to_numpy(), return_counts=True)\n",
    "    unique_test, counts_test = numpy.unique(Y_test.to_numpy(), return_counts=True)\n",
    "    print(\"Train - \", unique_train, counts_train)\n",
    "    print(\"Test - \", unique_test, counts_test)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train, columns = original_X_train.columns, index=original_X_train.index)\n",
    "    X_test = pd.DataFrame(X_test, columns = original_X_train.columns, index=original_X_test.index)\n",
    "    \n",
    "    X_train_imputed = pd.DataFrame(X_train_imputed, columns = original_X_train.columns, index=original_X_train.index)\n",
    "    X_test_imputed = pd.DataFrame(X_test_imputed, columns = original_X_train.columns, index=original_X_test.index)\n",
    "    \n",
    "    return df, X_train, X_test, Y_train, Y_test, X, Y, X_train_imputed, X_test_imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d761b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_val(model, X_train, Y_train, n_splits=10):\n",
    "    balacc_arr = []\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=123)\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X_train, Y_train)):\n",
    "        X_train1 = X_train.iloc[train_index]\n",
    "        X_test1 = X_train.iloc[test_index]\n",
    "        y_train1 = Y_train.iloc[train_index]\n",
    "        y_test1 = Y_train.iloc[test_index]\n",
    "\n",
    "        model.fit(X_train1, y_train1)\n",
    "\n",
    "        # auc calculation\n",
    "        y_scores = model.predict_proba(X_test1)\n",
    "\n",
    "        # bal acc\n",
    "        y_sc = y_scores[:, 1]\n",
    "        fpr, tpr, thresholds = roc_curve(y_test1, y_sc)\n",
    "        optimal_idx = np.argmax(np.sqrt(tpr * (1 - fpr)))\n",
    "        optimal_threshold = thresholds[optimal_idx]\n",
    "\n",
    "        model_pred = (y_sc >= optimal_threshold).astype(int)\n",
    "        confusion_matrix_model = confusion_matrix(y_test1, model_pred)\n",
    "        acc_bal = confusion_matrix_model.diagonal() / confusion_matrix_model.sum(axis=1)\n",
    "        balacc_arr.append(np.sum(acc_bal) / 2)\n",
    "\n",
    "    variance_bal = np.var(balacc_arr, ddof=1)\n",
    "\n",
    "    print(\"Cross validation variance Balance acc:\", variance_bal)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681f5333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr, optimal_idx):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.scatter(fpr[optimal_idx], tpr[optimal_idx], marker='o', color='black', label='Best') \n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "def optimal_thresh(model, X, Y):\n",
    "    y_scores = model.predict_proba(X)[:,1]\n",
    "    fpr, tpr, thresholds = roc_curve(Y, y_scores)\n",
    "    optimal_idx = np.argmax(np.sqrt(tpr * (1-fpr)))\n",
    "    optimal_threshold = thresholds[optimal_idx]\n",
    "    return optimal_threshold\n",
    "\n",
    "# def get_results(model, X, Y, pred):\n",
    "#     confusion_matrix_model = confusion_matrix(Y, pred)\n",
    "#     test_acc = model.score(X, Y)\n",
    "    \n",
    "#     results_table = [\n",
    "#         [\"Confusion Matrix\", confusion_matrix_model],\n",
    "#         [\"Accuracy\", test_acc]\n",
    "#     ]\n",
    "    \n",
    "#     print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "def evaluate_model(model, X_test, Y_test, optimal_threshold):\n",
    "    \n",
    "    xgb_pred = (model.predict_proba(X_test)[:,1] >= optimal_threshold).astype(int)\n",
    "    y_scores = model.predict_proba(X_test)\n",
    "    score = round(roc_auc_score(Y_test, y_scores[:, 1]), 4)\n",
    "    pred = model.predict(X_test)\n",
    "    confusion_matrix_model = confusion_matrix(Y_test, xgb_pred)\n",
    "    \n",
    "    acc = confusion_matrix_model.diagonal() / confusion_matrix_model.sum(axis=1)\n",
    "    avg_acc = np.sum(acc) / 2\n",
    "    f1 = metrics.f1_score(xgb_pred, Y_test, average='micro')\n",
    "    \n",
    "    results_table = [\n",
    "        [\"Test ROC Score\", score],\n",
    "        [\"Test Classwise Accuracy [Class 0, Class 1]\", acc],\n",
    "        [\"Test Average Accuracy\", avg_acc],\n",
    "        [\"Test F1 Score\", f1]\n",
    "    ]\n",
    "    \n",
    "    print(tabulate(results_table, headers=[\"Metric\", \"Value\"], tablefmt=\"fancy_grid\"))\n",
    "\n",
    "\n",
    "def train_model(model, X_train, Y_train, X_test, Y_test):\n",
    "    model = cross_val(model, X_train, Y_train)\n",
    "#     model = model.fit(X_train, Y_train)\n",
    "    optimal_threshold = optimal_thresh(model, X_test, Y_test)\n",
    "    pred = (model.predict_proba(X_test)[:, 1] >= optimal_threshold).astype(int)\n",
    "    optimal_threshold_train = optimal_thresh(model, X_train, Y_train)\n",
    "    pred_train = (model.predict_proba(X_train)[:, 1] >= optimal_threshold_train).astype(int)\n",
    "\n",
    "    optimal_threshold_test = optimal_thresh(model, X_test, Y_test)\n",
    "\n",
    "    evaluate_model(model, X_test, Y_test, optimal_threshold_test)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ab40e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(models, X_train, X_test, X_train_imputed, X_test_imputed, Y_train, Y_test):\n",
    "    trained_models = {}\n",
    "    for model in models:\n",
    "        X_t = X_train\n",
    "        X_te = X_test\n",
    "        model_name = model.__class__.__name__\n",
    "        if(model_name == 'AdaBoostClassifier' or model_name == 'RandomForestClassifier' or model_name == 'LogisticRegression'):\n",
    "            X_t = X_train_imputed\n",
    "            X_te = X_test_imputed\n",
    "        print(\"Model:\", model_name)\n",
    "        trained_model = train_model(model, X_t, Y_train, X_te, Y_test)\n",
    "        trained_models[model_name] = trained_model\n",
    "        print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "    return trained_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a35922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_important_features(best_n, X_train_feat, Y_train_feat):\n",
    "    original_X = X_train\n",
    "    fs = ReliefF()\n",
    "    fs.fit(X_train_feat, Y_train_feat)\n",
    "\n",
    "    feat_dict = {}\n",
    "\n",
    "    for feature_name, feature_score in zip(original_X.columns,\n",
    "                                           fs.feature_importances_):\n",
    "        feat_dict[feature_name] = feature_score\n",
    "\n",
    "    # sort and get most important features\n",
    "    feat_names = []\n",
    "    sorted_feat_dict = sorted(feat_dict.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    best = sorted_feat_dict[: best_n]\n",
    "\n",
    "    for i in best:\n",
    "        feat_names.append(i[0])\n",
    "\n",
    "    return feat_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_gender_specific_fields(df):\n",
    "    drop_list = ['Pt_MenarcheAge','Pt_RegMenstCyc','Pt_IrregMenstCycReas','Pt_CurrPreg','Pt_MiscarriageNum']\n",
    "    columns_to_drop_existing = [col for col in drop_list if col in df.columns]\n",
    "    df = df.drop(columns=columns_to_drop_existing,  axis = 1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa730129",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_gender_stratified_data(gender, train_, test_, train_imputed_, test_imputed_, Y_train_, Y_test_, variable):\n",
    "    # remove female specific features from male dataser\n",
    "    if gender == 0.5:\n",
    "        train_ = remove_gender_specific_fields(train_)\n",
    "        test_ = remove_gender_specific_fields(test_)\n",
    "        train_imputed = remove_gender_specific_fields(train_imputed_)\n",
    "        test_imputed = remove_gender_specific_fields(test_imputed_)\n",
    "        \n",
    "    # Update with proper value for females and males\n",
    "    train_mask = train_[variable] == gender\n",
    "    test_mask = test_[variable] == gender\n",
    "\n",
    "    train_mask_imputed = train_imputed_[variable] == gender\n",
    "    test_mask_imputed = test_imputed_[variable] == gender\n",
    "\n",
    "    X_train = train_.loc[train_mask].drop(response_variable, axis=1)\n",
    "    X_test = test_.loc[test_mask].drop(response_variable, axis=1)\n",
    "\n",
    "    X_train_imputed_ = train_imputed_.loc[train_mask_imputed].drop(response_variable, axis=1)\n",
    "    X_test_imputed_ = test_imputed_.loc[test_mask_imputed].drop(response_variable, axis=1)\n",
    "\n",
    "    Y_train = Y_train_.loc[train_mask]\n",
    "    Y_test = Y_test_.loc[test_mask]\n",
    "   \n",
    "    \n",
    "    return X_train, X_train_imputed_, Y_train, X_test, X_test_imputed_, Y_test\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
